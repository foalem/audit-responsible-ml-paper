{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f7a39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b96289ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_csv_files_in_folder(folder_path):\n",
    "    \n",
    "    csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "    \n",
    "    dfs = []\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            file_path = os.path.join(folder_path, csv_file)\n",
    "            df = pd.read_csv(file_path, sep=',', encoding='latin-1')\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {csv_file}: {str(e)}\")\n",
    "            \n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02063ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './'\n",
    "result_df = concatenate_csv_files_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8993b5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fit error  help</td>\n",
       "      <td>model = Sequential()\\r\\n\\r\\nmodel.add(Conv2D(3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>éªè¯ç éå</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>add a font file and fix the writing style</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4-6ä¸ªå­ç¬¦è½ç¨ä¸ä¸ªæ¨¡åå®ç°åï¼</td>\n",
       "      <td>ä½ å¥½ï¼ä½ çæ¨¡åææåå¤å¶äºï¼4ä¸ª...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>write labels err</td>\n",
       "      <td>writer.writerows(labels)\\r\\nTypeError: a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121412</th>\n",
       "      <td>Fix renew_ch</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121413</th>\n",
       "      <td>convert Tensorflow weights to Pytorch weights</td>\n",
       "      <td>I have converted Tensorflow weights to Pytorch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121414</th>\n",
       "      <td>In_channels in last conv should be renew_ch(320)?</td>\n",
       "      <td>https://github.com/zsef123/EfficientNets-PyTor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121415</th>\n",
       "      <td>Why you don't use any skip connection?</td>\n",
       "      <td>https://github.com/zsef123/EfficientNets-PyTor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121416</th>\n",
       "      <td>AttributeError: module 'torch.nn' has no attri...</td>\n",
       "      <td>I just use your model code, and report the err...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121417 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  \\\n",
       "0                                         fit error  help   \n",
       "1                                         éªè¯ç éå    \n",
       "2               add a font file and fix the writing style   \n",
       "3              4-6ä¸ªå­ç¬¦è½ç¨ä¸ä¸ªæ¨¡åå®ç°åï¼   \n",
       "4                                        write labels err   \n",
       "...                                                   ...   \n",
       "121412                                       Fix renew_ch   \n",
       "121413     convert Tensorflow weights to Pytorch weights    \n",
       "121414  In_channels in last conv should be renew_ch(320)?   \n",
       "121415             Why you don't use any skip connection?   \n",
       "121416  AttributeError: module 'torch.nn' has no attri...   \n",
       "\n",
       "                                                     body  \n",
       "0       model = Sequential()\\r\\n\\r\\nmodel.add(Conv2D(3...  \n",
       "1                                                     NaN  \n",
       "2                                                     NaN  \n",
       "3       ä½ å¥½ï¼ä½ çæ¨¡åææåå¤å¶äºï¼4ä¸ª...  \n",
       "4           writer.writerows(labels)\\r\\nTypeError: a b...  \n",
       "...                                                   ...  \n",
       "121412                                                NaN  \n",
       "121413  I have converted Tensorflow weights to Pytorch...  \n",
       "121414  https://github.com/zsef123/EfficientNets-PyTor...  \n",
       "121415  https://github.com/zsef123/EfficientNets-PyTor...  \n",
       "121416  I just use your model code, and report the err...  \n",
       "\n",
       "[121417 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97aca84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_english_french_rows(df, min_text_length=10):\n",
    "    \n",
    "    filtered_rows = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        title = row['title']\n",
    "        body = row['body']\n",
    "        if pd.notna(str(title)) and pd.notna(str(body)):\n",
    "            try:\n",
    "                title_lang = detect(str(title))\n",
    "                body_lang = detect(str(body))\n",
    "                \n",
    "                # Check if both title and body are in English or French\n",
    "                if (title_lang in ['en', 'fr'] and len(str(title)) >= min_text_length) and \\\n",
    "                   (body_lang in ['en', 'fr'] and len(str(body)) >= min_text_length):\n",
    "                    filtered_rows.append(row)\n",
    "            except:\n",
    "                print('An exception occurred')\n",
    "                pass \n",
    "            \n",
    "    filtered_df = pd.DataFrame(filtered_rows)\n",
    "    filtered_df.reset_index(drop=True, inplace=True)\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1d8f349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n",
      "An exception occurred\n"
     ]
    }
   ],
   "source": [
    "filtered_df = filter_english_french_rows(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba7b73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>numpy.core._internal.AxisError: axis 1 is out ...</td>\n",
       "      <td>è£",
       "å¥½ä¾èµï¼çæå¾çåï¼ç´æ¥è¿è¡ï...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only extract one word from gumbel softmax</td>\n",
       "      <td>In the code https://github.com/yala/text_nn/bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gumbel softmax instead of Reinforce</td>\n",
       "      <td>Hi,\\r\\n\\r\\nThank you for your code ! I have se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is log_softmax function missing in the Line 39...</td>\n",
       "      <td>I think log_softmax function should be added i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can this be applied to a regression problem?</td>\n",
       "      <td>Can this be applied to a regression problem?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44871</th>\n",
       "      <td>the meaning of depth div</td>\n",
       "      <td>Hi\\r\\n\\r\\nwhat is the meaning of `depth_div` u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44872</th>\n",
       "      <td>accuracy for the code</td>\n",
       "      <td>Hi,\\r\\n\\r\\nThanks for your code. Did you do so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44873</th>\n",
       "      <td>convert Tensorflow weights to Pytorch weights</td>\n",
       "      <td>I have converted Tensorflow weights to Pytorch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44874</th>\n",
       "      <td>Why you don't use any skip connection?</td>\n",
       "      <td>https://github.com/zsef123/EfficientNets-PyTor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44875</th>\n",
       "      <td>AttributeError: module 'torch.nn' has no attri...</td>\n",
       "      <td>I just use your model code, and report the err...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44876 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0      numpy.core._internal.AxisError: axis 1 is out ...   \n",
       "1              Only extract one word from gumbel softmax   \n",
       "2                    Gumbel softmax instead of Reinforce   \n",
       "3      Is log_softmax function missing in the Line 39...   \n",
       "4           Can this be applied to a regression problem?   \n",
       "...                                                  ...   \n",
       "44871                           the meaning of depth div   \n",
       "44872                              accuracy for the code   \n",
       "44873     convert Tensorflow weights to Pytorch weights    \n",
       "44874             Why you don't use any skip connection?   \n",
       "44875  AttributeError: module 'torch.nn' has no attri...   \n",
       "\n",
       "                                                    body  \n",
       "0      è£\n",
       "å¥½ä¾èµï¼çæå¾çåï¼ç´æ¥è¿è¡ï...  \n",
       "1      In the code https://github.com/yala/text_nn/bl...  \n",
       "2      Hi,\\r\\n\\r\\nThank you for your code ! I have se...  \n",
       "3      I think log_softmax function should be added i...  \n",
       "4           Can this be applied to a regression problem?  \n",
       "...                                                  ...  \n",
       "44871  Hi\\r\\n\\r\\nwhat is the meaning of `depth_div` u...  \n",
       "44872  Hi,\\r\\n\\r\\nThanks for your code. Did you do so...  \n",
       "44873  I have converted Tensorflow weights to Pytorch...  \n",
       "44874  https://github.com/zsef123/EfficientNets-PyTor...  \n",
       "44875  I just use your model code, and report the err...  \n",
       "\n",
       "[44876 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8de0ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv('Issue_collected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69537d10",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Download the stopwords corpus\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnltk\u001b[49m\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstopwords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwordnet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "# Download the stopwords corpus\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22711183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    remove_infrequent=True\n",
    "    threshold = 2\n",
    "    infrequent_threshold=2\n",
    "    # drop duplicates\n",
    "#     df = df.drop_duplicates()\n",
    "    # drop NAN\n",
    "    df = df.dropna()\n",
    "    # Combine title and body into a single document\n",
    "    df.loc[:, 'document'] = df['title'] + ' ' + df['body']\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    df.loc[:, 'document'] = df.loc[:, 'document'].str.lower()\n",
    "\n",
    "    # Remove special characters and punctuation\n",
    "    df.loc[:, 'document'] = df.loc[:, 'document'].str.replace(r'[^a-zA-Z\\s]', '')\n",
    "\n",
    "    # Remove numbers\n",
    "    df.loc[:, 'document'] = df.loc[:, 'document'].str.replace(r'\\d+', '')\n",
    "    \n",
    "    # Remove Python syntax\n",
    "    df.loc[:, 'document'] = df.loc[:, 'document'].apply(remove_python_syntax)\n",
    "    \n",
    "    # Remove URLs\n",
    "    df.loc[:, 'document'] = df.loc[:, 'document'].apply(lambda x: re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', x))\n",
    "\n",
    "    # Remove images\n",
    "    df.loc[:, 'document'] = df.loc[:, 'document'].apply(lambda x: re.sub(r'\\bimage\\S+', '', x))\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df.loc[:, 'document'] = df.loc[:, 'document'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    df.loc[:, 'document'] = df.loc[:, 'document'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "    \n",
    "#     # Remove infrequent words if enabled\n",
    "#     if remove_infrequent:\n",
    "#         df['document'] = df['document'].apply(lambda x: remove_infrequent_words(x, infrequent_threshold))\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    df.loc[:, 'document'] = df.loc[:, 'document'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split()]))\n",
    "    \n",
    "    # Remove single characters\n",
    "    df['document'] = df['document'].apply(remove_single_characters)\n",
    "    \n",
    "    # Remove single-character words\n",
    "    df['document'] = df['document'].apply(lambda x: ' '.join([word for word in x.split() if len(word) > 1]))\n",
    "    \n",
    "    # Remove punctuation\n",
    "    df['document'] = df['document'].apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "    \n",
    "    # Remove numbers or words starting or ending with a number\n",
    "#     df['document'] = df['document'].apply(lambda x: re.sub(r'\\b\\d+\\w*\\b|\\b\\w*\\d+\\b', '', x))\n",
    "    \n",
    "    # Remove non-word and non-space characters, words containing digits, and emojis\n",
    "    df['document'] = df['document'].apply(lambda x: re.sub(r'[^\\w\\s]|(\\w*\\d\\w*)|[\\U0001F300-\\U0001F6FF]', '', x))\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "def remove_python_syntax(text):\n",
    "    # Remove Python code blocks enclosed in triple backticks\n",
    "    text = re.sub(r'```[\\s\\S]*?```', '', str(text))\n",
    "\n",
    "    # Remove Python code blocks enclosed in double backticks\n",
    "    text = re.sub(r'``[\\s\\S]*?``', '', str(text))\n",
    "\n",
    "    # Remove Python code blocks enclosed in single backticks\n",
    "    text = re.sub(r'`[\\s\\S]*?`', '', str(text))\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', str(text))\n",
    "    \n",
    "    return text\n",
    "\n",
    "def remove_infrequent_words(text, threshold):\n",
    "        words = text.split()\n",
    "        word_counts = Counter(words)\n",
    "        infrequent_words = [word for word, count in word_counts.items() if count < threshold]\n",
    "        return ' '.join([word for word in words if word not in infrequent_words])\n",
    "    \n",
    "def remove_single_characters(text):\n",
    "        return ' '.join([word for word in text.split() if len(word) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e424af",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_df = preprocess_text(filtered_df)\n",
    "process_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a02eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_colwidth', None):  \n",
    "    display(process_df[\"document\"][32342])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b8b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_df[\"body\"][32342]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unigram_bigram(texts):\n",
    "    # Tokenize the texts\n",
    "    tokenized_texts = [word_tokenize(text) for text in texts]\n",
    "\n",
    "    # Build bigrams\n",
    "    bigram = Phrases(tokenized_texts, min_count=5, threshold=10)\n",
    "    bigram_phraser = Phraser(bigram)\n",
    "    bigram_texts = [bigram_phraser[doc] for doc in tokenized_texts]\n",
    "\n",
    "    return tokenized_texts, bigram_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceff3376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_num_topics(texts, num_topics_range):\n",
    "    \n",
    "    tokenized_texts, bigram_texts = build_unigram_bigram(texts)\n",
    "#     print(tokenized_texts)\n",
    "    # Tokenize the texts\n",
    "#     tokenized_texts = [text.split() for text in texts]\n",
    "\n",
    "    # Create the dictionary\n",
    "    dictionary = Dictionary(bigram_texts)\n",
    "\n",
    "    # Create the corpus\n",
    "    corpus = [dictionary.doc2bow(text) for text in bigram_texts]\n",
    "\n",
    "    coherence_scores = []\n",
    "    for num_topics in num_topics_range:\n",
    "        # Build the LDA model\n",
    "        lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, iterations=11, random_state=100, passes=10)\n",
    "\n",
    "        # Compute coherence score\n",
    "        coherence_model = CoherenceModel(model=lda_model, texts=bigram_texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_score = coherence_model.get_coherence()\n",
    "        coherence_scores.append(coherence_score)\n",
    "\n",
    "    return coherence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79db5f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics_range = [i for i in range(5, 60, 1)]  # Adjust the range as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dfeffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_scores = find_optimal_num_topics(process_df['document'].to_list(), num_topics_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531236b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coherence_scores(num_topics_range, coherence_scores):\n",
    "    # Plot the coherence scores\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(num_topics_range, coherence_scores, marker='o')\n",
    "    plt.xlabel('Number of Topics')\n",
    "    plt.ylabel('Coherence Score')\n",
    "    plt.title('Coherence Scores vs. Number of Topics')\n",
    "    plt.xticks(num_topics_range)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127536e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to plot the coherence scores\n",
    "plot_coherence_scores(num_topics_range, coherence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93985f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lda_model(texts, num_topics=6):\n",
    "    tokenized_texts, bigram_texts = build_unigram_bigram(texts)\n",
    "\n",
    "    # Create the dictionary\n",
    "    dictionary = Dictionary(bigram_texts)\n",
    "\n",
    "    # Create the corpus\n",
    "    corpus = [dictionary.doc2bow(text) for text in bigram_texts]\n",
    "\n",
    "    # Build the LDA model\n",
    "    lda_model = LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, iterations=11, random_state=100, passes=10)\n",
    "\n",
    "    # Get the topics and keywords\n",
    "    topics = lda_model.show_topics(num_topics=num_topics, formatted=False)\n",
    "\n",
    "    # Extract the keywords from the topics\n",
    "    topic_keywords = []\n",
    "    for topic_id, topic in topics:\n",
    "        keywords = [word for word, _ in topic]\n",
    "        topic_keywords.append(keywords)\n",
    "\n",
    "    return lda_model, topics, dictionary, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d768ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_, topics_, dictionnary_, corpus_ = train_lda_model(process_df['document'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d716fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_topics(lda_model, corpus, dictionary):\n",
    "    pyLDAvis.enable_notebook()\n",
    "    # Convert the Gensim LDA model to pyLDAvis format\n",
    "    vis_data = pyLDAvis.gensim.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "    # Display the interactive visualization\n",
    "    return pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_topics(model_, corpus_, dictionnary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8637f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
