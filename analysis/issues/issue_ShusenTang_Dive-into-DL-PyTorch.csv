title,body
3.16 实战Kaggle比赛：房价预测 np转成tensor会报错问题,"**bug描述**
![image](https://user-images.githubusercontent.com/66686828/234868676-6c91af76-9e9d-4d93-bcb2-8b22a5b0d32e.png)


**版本信息**
pytorch:1.8.0+cu111
torchvision:0.9.1+cu101
torchtext:0.9.0
...
"
3.5节fashion-mnist.ipynb下载FashionMNIST数据集太慢，有其他载入数据集的办法吗（jupyternotrbook）,"**bug描述**
3.5节fashion-mnist.ipynb下载FashionMNIST数据集太慢

"
现在pytorch的版本已经修改了很多东西希望能对内容进行更新,现在pytroch中对张量使用view方法后得到的张量和源张量不再共享内存了
Deprecated use of IPython.display.set_matplotlib_formats,"**bug描述**
![image](https://user-images.githubusercontent.com/41790869/158048679-88574e58-eea5-4f5a-a25b-47050b0402e7.png)
3.2.1部分代码
![image](https://user-images.githubusercontent.com/41790869/158048692-1c52cc91-8a11-4fe7-8397-094fd47fb1d4.png)


**版本信息**
pytorch:1.10.2
torchvision:
torchtext:
...
"
请问咱们这个pytorch版本有纸质版吗？,如题。觉得这本书写的挺好的，想多看看。
3.9节的net中是否要加入softmax,"这里在return时不需要softmax吗？

```python
def net(X):
    X = X.view((-1, num_inputs))
    H = relu(torch.matmul(X, W1) + b1)
    return torch.matmul(H, W2) + b2
```"
5.2节步幅内容错误,"**bug描述**
5.2节 关于步幅下的 pad的描述出错 应该是p = k - s

**版本信息**
pytorch:无
torchvision:无
torchtext:无
...
"
Dev,add a new word
5.6.2 AlexNet最后卷积层的输出大小应该为256*6*6,"**AlexNet最后卷积层的输出大小**

AlexNet最后卷积层的输出应该是256 * 6 * 6吧， (13 - 3) / 2 + 1 = 6

![image](https://user-images.githubusercontent.com/22441405/136881255-99bfaa72-3ff4-450e-9093-9a9d3acd413e.png)

我还没有训练，但是原文按照 256 * 5 * 5 来训练没问题吗？

**版本信息**
pytorch: 1.8.1
torchvision: 0.8.0
torchtext:
...
"
4.4.2 函数报错问题,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等
![image](https://user-images.githubusercontent.com/59960539/136193659-72ac2d3c-c7a3-4d4a-bc3c-0feea78a7dca.png)
![image](https://user-images.githubusercontent.com/59960539/136193734-6ba5d7fb-0161-468b-a681-6595fb3db4a6.png)
在1图中，使用的是MyDense()类，再2图中调用使用MyListDense()，是否应该改正
**版本信息**
pytorch:
torchvision:
torchtext:
...
"
10.7.2 torchtext 好像版本更新了，没有stoi属性，且换成新版本get_stoi依旧由于,"![image](https://user-images.githubusercontent.com/63043716/135760882-987cb76e-7a4a-404d-966b-b40c14749916.png)
报错原因在于，训练集中有些滤去的词不在vocab里，想询问一下，除了直接散去这些不在里面的词，还有什么更好的方法解决"
10.4 子词嵌入（fastText）有书写错误,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等
pytorch版本是
```
我们得到所有长度为3的子词：“<wh>”“whe”“her”“ere”“<re>”以及特殊子词“<where>”。
```
原书是
```
我们得到所有长度为3的子词：“<wh”“whe”“her”“ere”“re>”以及特殊子词“<where>”。
```
差别在于 第一个字词<wh 和最后一个字词re>

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
5.6节的描述错误,"**bug描述**
![image](https://user-images.githubusercontent.com/40693000/133453350-2f814333-4e43-458a-8168-9efa087ea561.png)

这里应当是 Sigmod输入趋近于负无穷和正无穷的话，梯度趋近于0吧

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
2.3.3梯度结果问题请教,"**bug描述**
在按照教程2.3.3梯度章节中 
“
# 再来反向传播一次，注意grad是累加的
out2 = x.sum()
out2.backward()
print(x.grad)
”
时我的返回结果是
tensor([[1., 1.],
        [1., 1.]])
如图
![image](https://user-images.githubusercontent.com/34927296/129324138-09c6d8ad-e098-47cf-a798-b4eb49c611d3.png)
请问是我的输入有问题么？

**版本信息**
pytorch: 1.9.0
torchvision: 0.10.0
torchtext: None
...
"
Add pdf build scripts and Github Actions release,"`docs/compile.py` 和 `docs/utils.py` 实现了将文档编译为 pdf 版本，构建过程会在 `docs/build` 下进行。
`docs/tex/` 文件夹下为 pdf 的 latex 模板和封面。
`.github/workflows/release-pdf.yml` 为自动化构建 pdf 的 Github Actions 脚本配置文件。
预览版测试 release 可参考 [https://github.com/silverling/Dive-into-DL-PyTorch/releases](https://github.com/silverling/Dive-into-DL-PyTorch/releases)

如需要在本地构建，请安装 `python3`, `texlive`，`pandoc`，`prettier` 和相关字体依赖，然后执行以下命令：
```bash
git clone https://github.com/ShusenTang/Dive-into-DL-PyTorch.git --depth 1
cd Dive-into-DL-PyTorch/docs # 由于脚本中采用相对路径，故需要在此路径下执行
python3 ./compile.py
```"
2.2.2节符号错误：应该是+=1而非-=1,"**bug描述**
位置：2.2.2节
截图：
![image](https://user-images.githubusercontent.com/14107297/124296223-4b4a5880-db8c-11eb-8c56-48b2ae8f952b.png)


**版本信息**
pytorch:
torchvision:
torchtext:
...
"
章节 5.6.2 AlexNet 第一个卷积层的comment描述有出入,"Comment:
`# in_channels, out_channels, kernel_size, stride, padding` 但是实际传参4个，即padding默认为0，可能会造成误解。"
9.4 锚框一节里的画出bbox 的注释书写错误,"```
show_bboxes(fig.axes, boxes[250, 250, :, :] * bbox_scale,
            ['s=0.75, r=1', 's=0.75, r=2', 's=0.55, r=0.5', 's=0.5, r=1', 's=0.25, r=1'])
```

根据文章中的(s1, r1),(s1,r2), (s1,r3)第三个的注释应该是's=0.75, r=0.5', 如下所示：

```
show_bboxes(fig.axes, boxes[250, 250, :, :] * bbox_scale,
            ['s=0.75, r=1', 's=0.75, r=2', 's=0.75, r=0.5', 's=0.5, r=1', 's=0.25, r=1'])
```
"
Merge pull request #1 from ShusenTang/master,Run in a docker container (#140)
4.5.2.1节的书写错误,"**bug描述**
没有bug，是书写错误

**版本信息**
pytorch:
torchvision:
torchtext:
...
原文：
> state_dict是一个从参数名称**隐射**到参数**Tesnor**的字典对象。

疑似出错的地方：
隐射 => 映射？
Tesnor => Tensor？"
test,
3.7节报错问题,"报错是这一句
**d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)**
报错如下：
**RuntimeError: Tensor for 'out' is on CPU, Tensor for argument #1 'self' is on CPU, but expected them to be on GPU (while checking arguments for addmm)**
在源代码末尾加上.cuda（）依旧报错，求解
![image](https://user-images.githubusercontent.com/67496688/106447182-24dca000-64bc-11eb-82e9-75fd5334541c.png)
"
期待FCN章节的更新,"这本书讲的比较系统，讲的深入浅出，本人获益匪浅，希望后续能有FCN章节的更新。
"
9.1和9.2的数据集,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等

您好，9.1和9.2的数据集图片是不是没放上去

**版本信息**
pytorch:1.5
torchvision:
torchtext:
...
"
3.6.6   评价net在data_iter上的准确性,"正常copy，出现下面问题，不知道怎么处理，求帮助

def evaluate_accuracy(data_iter, net):
    acc_sum, n = 0.0, 0
    for X, y in data_iter:
        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()
        n += y.shape[0]
    return acc_sum / n
print(evaluate_accuracy(test_iter, net))

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-35-0c1a0f49bc5c> in <module>
      6         n += y.shape[0]
      7     return acc_sum / n
----> 8 print(evaluate_accuracy(test_iter, net))

<ipython-input-35-0c1a0f49bc5c> in evaluate_accuracy(data_iter, net)
      3     acc_sum, n = 0.0, 0
      4     for X, y in data_iter:
----> 5         acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()
      6         n += y.shape[0]
      7     return acc_sum / n

<ipython-input-26-3f7ef5a122d4> in net(X)
      1 def net(X):
----> 2     return softmax(torch.mm(X.view((-1, num_inputs)), W) + b)

RuntimeError: The size of tensor a (10) must match the size of tensor b (3) at non-singleton dimension 1
**版本信息**
pytorch:
torchvision:
torchtext:
...
"
没有9.7节单发多框检测（SSD）的内容,"**bug描述**
如题，没有9.7节SSD的内容，包括docs、code

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
"6.5.2 RNN简洁实现,使用相邻采样时,state在新的epoch中未被初始化","**bug描述**
![2020-11-06 16-43-35 的屏幕截图](https://user-images.githubusercontent.com/35167412/98346142-870a3e00-2050-11eb-84e3-0d3c50df1642.png)
`state = None`放在了`for epoch in range(num_epochs)`上. 因此,在新的epoch中,state实际上没有被初始化,而是使用上一epoch最后一次迭代最后一个时间步的state, 这样并不合理. 
要把`state = None`放在了`for epoch in range(num_epochs)`下面,`for X, Y in data_iter`上面

**版本信息**
pytorch: 1.6.0
torchvision: 0.7.0
torchtext:
...
"
关于6.3.3 随机采样和相邻采样的疑惑,"**bug描述**
```
# 本函数已保存在d2lzh_pytorch包中方便以后使用
def data_iter_random(corpus_indices, batch_size, num_steps, device=None):
    # 减1是因为输出的索引x是相应输入的索引y加1
    num_examples = (len(corpus_indices) - 1) // num_steps
    epoch_size = num_examples // batch_size
    example_indices = list(range(num_examples))
    random.shuffle(example_indices)

    # 返回从pos开始的长为num_steps的序列
    def _data(pos):
        return corpus_indices[pos: pos + num_steps]
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    for i in range(epoch_size):
        # 每次读取batch_size个随机样本
        i = i * batch_size
        batch_indices = example_indices[i: i + batch_size]
        X = [_data(j * num_steps) for j in batch_indices]
        Y = [_data(j * num_steps + 1) for j in batch_indices]
        yield torch.tensor(X, dtype=torch.float32, device=device), torch.tensor(Y, dtype=torch.float32, device=device)
```
以上是随机采样的写法，但是觉得有两个问题。首先，因为`for i in range(epoch_size)`的关系，所以实际上每一次都是从下标为0的开始采样。对于下面所给的测试，实际上`x`只能在0-23产生batch，也就是x的batch一直都不包括24,25,26,27,28。
```
# 测试
my_seq = list(range(30))
for X, Y in data_iter_random(my_seq, batch_size=2, num_steps=6):
    print('X: ', X, '\nY:', Y, '\n')

# 所给的结果
X:  tensor([[18., 19., 20., 21., 22., 23.],
        [12., 13., 14., 15., 16., 17.]]) 
Y: tensor([[19., 20., 21., 22., 23., 24.],
        [13., 14., 15., 16., 17., 18.]]) 

X:  tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],
        [ 6.,  7.,  8.,  9., 10., 11.]]) 
Y: tensor([[ 1.,  2.,  3.,  4.,  5.,  6.],
        [ 7.,  8.,  9., 10., 11., 12.]]) 
```
Q1：
那其实在实现随机采样的时候，是不是应该保证有一部分epoch包含的batch有24,25,26,27,28(不知道我有没有理解错)。同理，在相邻采样中也有同样的情况。
Q2:
此外，上面的写法生成一定是batch_size=2的数据，当有数据剩余且数据量小于`batch_size=2`的数据量时就不会生成。但是在全连接和CNN中，我们读取的小批量数据在最后一个batch中数据量往往小于batch_size。因此在这里，假设上面的测试剩余了大于`batch_size=1`的数据（如设置`my_seq = list(range(32))`，此时有8个数据未被抽取），是否继续采样一个batch_size=1的数据，望解惑!
```
# Q2的情况如下：
# 测试
my_seq = list(range(32))
for X, Y in data_iter_random(my_seq, batch_size=2, num_steps=6):
    print('X: ', X, '\nY:', Y, '\n')

# 结果（这里包含了0<batch_size<=2的情况）
X:  tensor([[18., 19., 20., 21., 22., 23.],
        [ 0.,  1.,  2.,  3.,  4.,  5.]]) 
Y: tensor([[19., 20., 21., 22., 23., 24.],
        [ 1.,  2.,  3.,  4.,  5.,  6.]]) 

X:  tensor([[12., 13., 14., 15., 16., 17.],
        [24., 25., 26., 27., 28., 29.]]) 
Y: tensor([[13., 14., 15., 16., 17., 18.],
        [25., 26., 27., 28., 29., 30.]]) 

X:  tensor([[ 6.,  7.,  8.,  9., 10., 11.]]) 
Y: tensor([[ 7.,  8.,  9., 10., 11., 12.]]) 
```
以下是我另外写随机采样的，保证了我上述说的情况
```
def data_iter_random(corpus_indices, batch_size, num_steps, device=None):
    # 减1是因为输出的索引x是相应输入的索引y加1
    num_examples = (len(corpus_indices) - 1) // num_steps
    # 随机抽样的起始位置
    sample_start = np.random.randint((len(corpus_indices) - 1) % num_steps + 1)
    example_indices = np.arange(sample_start, len(corpus_indices), num_steps)[:num_examples]
    np.random.shuffle(example_indices)
    
    # 转gpu
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 每个读取batch_size个随机样本
    for idx in np.arange(0, len(example_indices), batch_size):
        batch_example = example_indices[idx:(idx+batch_size)]
        x = [corpus_indices[pos:(pos+num_steps)] for pos in batch_example]
        y = [corpus_indices[(pos+1):(pos+1+num_steps)] for pos in batch_example]
        yield torch.tensor(x, dtype=torch.float32, device=device), torch.tensor(y, dtype=torch.float32, device=device)
```
测试结果
```
my_seq = list(range(30))
for X, Y in data_iter_random(my_seq, batch_size=2, num_steps=6):
    print('X: ', X, '\nY:', Y, '\n')

# 结果:
X:  tensor([[14., 15., 16., 17., 18., 19.],
        [ 8.,  9., 10., 11., 12., 13.]], device='cuda:0') 
Y: tensor([[15., 16., 17., 18., 19., 20.],
        [ 9., 10., 11., 12., 13., 14.]], device='cuda:0') 

X:  tensor([[ 2.,  3.,  4.,  5.,  6.,  7.],
        [20., 21., 22., 23., 24., 25.]], device='cuda:0') 
Y: tensor([[ 3.,  4.,  5.,  6.,  7.,  8.],
        [21., 22., 23., 24., 25., 26.]], device='cuda:0')
```

**版本信息**
pytorch: 1.6.0
torchvision: 0.7.0
torchtext:
...
"
5.5.1 节 LeNet 全连接层的参数有问题,"**bug描述**
```python
self.fc = nn.Sequential(
            nn.Linear(16*4*4, 120),
            nn.Sigmoid(),
            nn.Linear(120, 84),
            nn.Sigmoid(),
            nn.Linear(84, 10)
)
第二行nn.Linear的第一个参数是不是应该是16*5*5
英文版的对应这一行的代码就是
nn.Linear(in_features=16*5*5, out_features=120),

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
数学公式无法显示,"**bug描述**
markdown文档所有数学公式无法显示

**版本信息**
"
修改readme文档,
3.9.4节W1和W2的类型问题,"**bug描述**
按3.9.4小节的net函数来计算，在我的环境里面报错了
```
def net(X):
    X = X.view((-1, num_inputs))
    H = relu(torch.matmul(X, W1) + b1)
    return torch.matmul(H, W2) + b2

loss = torch.nn.CrossEntropyLoss()

num_epochs, lr = 5, 100.0
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr)
```
错误如下：
```
RuntimeError  Traceback (most recent call last)
<ipython-input-52-c1201a53ebe9> in <module>
      1 num_epochs, lr = 5, 100.0
----> 2 d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr)

~/liang/d2lzh_pytorch.py in train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr, optimizer)
     84         train_l_sum, train_acc_sum, n = 0.0, 0.0, 0
     85         for X, y in train_iter:
---> 86             y_hat = net(X)
     87             l = loss(y_hat, y).sum()
     88 

<ipython-input-50-c182b51c4bb0> in net(X)
      1 def net(X):
      2     X = X.view((-1, num_inputs))
----> 3     H = relu(torch.matmul(X, W1) + b1)
      4     return torch.matmul(H, W2) + b2

RuntimeError: Expected object of scalar type Float but got scalar type Double for argument #2 'mat2' in call to _th_mm
```

**版本信息**
pytorch: 1.4.0
torchvision:0.5.0
torchtext:
...
"
3.6节train_ch3函数loss计算和sgd问题,"**bug描述**
3.6节train_ch3函数，如果传入的loss已经是求过平均的，train_l_sum每次只累加一个batch的平均值，最后却除以总样本数，打印的loss结果就会很小，例如3.9节的调用。

如果每个batch不一样大（例如Fashion-MNIST设置batch_size=256时，最后一个batch是96），当optimizer=None时，默认的sgd传入batch_size应该会在最后一个batch造成误差，似乎应该使用y.shape[0]。

另外train_ch5是用batch_count，如果batch大小不一致，最后打印的loss也应该会有微小误差。

```python
def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,
              params=None, lr=None, optimizer=None):
    for epoch in range(num_epochs):
        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0
        for X, y in train_iter:
            y_hat = net(X)
            l = loss(y_hat, y).sum()
            
            # 梯度清零
            if optimizer is not None:
                optimizer.zero_grad()
            elif params is not None and params[0].grad is not None:
                for param in params:
                    param.grad.data.zero_()
            
            l.backward()
            if optimizer is None:
                sgd(params, lr, batch_size)
            else:
                optimizer.step()  # “softmax回归的简洁实现”一节将用到
            
            
            train_l_sum += l.item()
            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()
            n += y.shape[0]
        test_acc = evaluate_accuracy(test_iter, net)
        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'
              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))
```

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
在http://tangshusen.me/Dive-into-DL-PyTorch/#/?id=%e9%a3%9f%e7%94%a8%e6%96%b9%e6%b3%95中，第一章简介中有一个食用方法，是否应该更改为使用方法,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等
面向人群
本项目面向对深度学习感兴趣，尤其是想使用PyTorch进行深度学习的童鞋。本项目并不要求你有任何深度学习或者机器学习的背景知识，你只需了解基础的数学和编程，如基础的线性代数、微分和概率，以及基础的Python编程。

食用方法
方法一

"
There is a line of redundant code in 7.3.1,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等

**版本信息**
pytorch:
torchvision:
torchtext:
...
%matplotlib inline
import numpy as np
import time
import torch
from torch import nn, optim
import sys
sys.path.append("".."") 
import d2lzh_pytorch as d2l

def get_data_ch7():  # 本函数已保存在d2lzh_pytorch包中方便以后使用
    data = np.genfromtxt('../../data/airfoil_self_noise.dat', delimiter='\t')
    data = (data - data.mean(axis=0)) / data.std(axis=0)
    return torch.tensor(data[:1500, :-1], dtype=torch.float32), \
    torch.tensor(data[:1500, -1], dtype=torch.float32) # 前1500个样本(每个样本5个特征)

features, labels = get_data_ch7()
features.shape # torch.Size([1500, 5])

"
Fix README.md Spelling Mistakes,Modify spelling error
网站不挂vpn好像打不开了,"**bug描述**
`https://tangshusen.me/Dive-into-DL-PyTorch/` 在国内不挂vpn好像打不开了

From：中国 浙江 杭州 联通 2020-08-07 20:46:48
"
请问什么时候才会出目标检测的Pytorch代码？,"如题，感觉目前只有mxnet版本的，Pytorch这里还没有相关的教程，希望能够出一些目标检测，语义分割的教程。
"
5.5节train_ch5函数中batch_count变量的定义位置有疑问,"**bug描述**
为什么要把batch_count定义在“for epoch in range”循环外？这样即使每个epoch得到的train_l_sum相同，越往后面的epoch算出的loss也会越小，似乎不合理。

```
def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):
    net = net.to(device)
    print(""training on "", device)
    loss = torch.nn.CrossEntropyLoss()
    batch_count = 0
    for epoch in range(num_epochs):
        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()
        for X, y in train_iter:
            X = X.to(device)
            y = y.to(device)
            y_hat = net(X)
            l = loss(y_hat, y)
            optimizer.zero_grad()
            l.backward()
            optimizer.step()
            train_l_sum += l.cpu().item()
            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()
            n += y.shape[0]
            batch_count += 1
        test_acc = evaluate_accuracy(test_iter, net)
        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'
              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))
```

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
2.2.1创建tensor uniform,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等
2.2.1创建tensor中给的创建tensor的表格里的uniform,查了下文档好像没有直接这个操作
![image](https://user-images.githubusercontent.com/17122734/87870671-efb7a700-c9dc-11ea-98cd-2649cd361d0b.png)
只有torch.Tensor(3, 3).uniform_(-1, 1)这种用法
**版本信息**
pytorch:
torchvision:
torchtext:
...
"
"6.4节的 rnn(input,state,params)  函数理解","请问其中的 H,=state 怎么理解？
,=是什么意思？
请问最后 return outputs, (H,) 中的 (H,) 又该如何理解？


"
第六章6.4节循环神经网络，官方注释不合理，容易误解！！！,"**bug描述**
关于RNN (循环神经网络）相邻采样为什么在每次迭代之前都需要将参数detach，官方解释不合理！
detach 根本不是为了防止梯度计算开销过大，因为pytorch是动态计算图，小批量反向传播完已经自动销毁图，下一次的计算图根本不会反向传播到之前的小批量图，detach的唯一作用是防止反向传播到隐藏状态时由于之前计算图的销毁而导致传播出错，因为 隐藏状态H0 并不是一个叶子节点！！！
我觉得你们在翻译这个的时候，可能未考虑到  MaxNet 支持静态图，这个解释对于MaxNet 静态图时合理的，但对pytorch就不适合了！！！
![image](https://user-images.githubusercontent.com/33288114/87238183-edc87380-c431-11ea-8d16-ac0f5a97cd59.png)

**理由**
https://www.cnblogs.com/catnofishing/p/13287322.html?tdsourcetag=s_pctim_aiomsg
"
"5.5LeNet 非错误,初学者的一个小疑问","**bug描述**
train_ch5函数中
train_l_sum += l.cpu().item()
train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()

为什么需要将误差建立在cpu上

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
7.4.3译者加的个人注解,"**bug描述**
译者在7.4.3从零开始实现这一节加了个人注解：
> 注：个人认为这里不应该是“加权平均”而应该是“加权和”，因为根据7.4.2.2节分析，加权平均最后除以了 <a href=""https://www.codecogs.com/eqnedit.php?latex=\inline&space;1-\gamma"" target=""_blank""><img src=""https://latex.codecogs.com/png.latex?\inline&space;1-\gamma"" title=""1-\gamma"" /></a>，所以就相当于没有进行平均

这里有点疑惑，原文上面说  <img src=""https://latex.codecogs.com/png.latex?\inline&space;v_t&space;\leftarrow&space;\gamma&space;v_{t-1}&space;&plus;&space;(1-\gamma)&space;\frac{\eta_t}{1-\gamma}{}&space;g_t"" title=""v_t \leftarrow \gamma v_{t-1} + (1-\gamma) \frac{\eta_t}{1-\gamma}{} g_t"" />  对应的序列是 <a href=""https://www.codecogs.com/eqnedit.php?latex=\inline&space;\eta_{t-i}g_{t-i}/(1-\gamma)"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\inline&space;\eta_{t-i}g_{t-i}/(1-\gamma)"" title=""\eta_{t-i}g_{t-i}/(1-\gamma)"" /></a>，这里多出来的 <img src=""https://latex.codecogs.com/gif.latex?\inline&space;1-\gamma"" title=""1-\gamma"" />是不是就是除以的数呢，如果这样的话其实是有做平均的，不知道这样理解对不对？"
你好，关于chap5 的5.2节卷积公式有疑问。,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等
![Uploading image.png…]()
和之前学过的完全不一样：
out_d=(in_d-k+2p)/s + 1
但是这本书里的公式为：
out_d=(in_d-k+p+s)/s + 1
p==s???
一般没听说默认步长一定等于padding吧？而且，padding这本书讲的也让人不明白，如果设定了padding是多少，那就是宽高都填1倍？这本书里是宽高都填1/2倍？卷积这部分真的是蒙了。用了那么久的卷积给我整不会了。

**版本信息**
pytorch:
torchvision:
torchtext:
...
。"
3.3.3节代码问题,"**bug描述**
缺少关键代码
import torch.nn as nn
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等
![3 3节代码问题](https://user-images.githubusercontent.com/49180284/85817144-c4f07f00-b79f-11ea-9d8d-3f038d5b294f.PNG)


**版本信息**
pytorch: 1.5.1
torchvision: 0.6.1
torchtext: 如上
...
"
4.1.3 中提到的get_constant函数是MXNet中的,按照自己的理解，将“get_constant函数”部分改了一下
Run in a docker container,
错别字,是手快了？还是？
3.10出现运行错误,"**bug描述**
#
![2020-06-16_210738](https://user-images.githubusercontent.com/57249328/84780174-d5725e00-b017-11ea-8308-06b849930f8a.png)

*版本信息**
pytorch:1.1
torchvision:
torchtext:
...
"
readme文件错别字,"**bug描述**
readme中的“食用方法”应为“使用方法”

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
pytorch,动手学习深度学习
3.5 kaggle房价预测代码疑问,"**bug描述**
请问下列代码中的torch.max()和torch.sqrt()代码为什么不会报错?
我尝试了解max和sqrt函数的作用，单独尝试torch.max(tensorA, torch.tensor(1.0))会报错：
Expected object of scalar type Long but got scalar type Float for argument #2 'other'

在PyTorch官方文档中，torch.sqrt()只有一个参数。

def log_rmse(net, features, labels):
    with torch.no_grad():
        # 将小于1的值设成1， 使得取对数时数值更稳定
        clipped_preds = torch.max(net(features), torch.tensor(1.0))
        rmse = torch.sqrt(loss(clipped_preds.log(), labels.log()))
    return rmse.item()

"
3.6_softmax-regression-scratch.ipynb 运行错误,"**bug描述**
3.6_softmax-regression-scratch.ipynb ""3.6.8 预测""下的cell运行错误:
RuntimeError                              Traceback (most recent call last)
<ipython-input-16-6d43c8fd6a29> in <module>
      2 
      3 true_labels = d2l.get_fashion_mnist_labels(y.numpy())
----> 4 pred_labels = d2l.get_fashion_mnist_labels(net(X).argmax(dim=1).numpy())
      5 titles = [true + '\n' + pred for true, pred in zip(true_labels, pred_labels)]
      6 

RuntimeError: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead.

原版本：
pytorch:0.4.1
torchvision:0.2.1

**版本信息**
pytorch:1.5.0
torchvision:0.6.0
torchtext:
...
"
描述错误,"**bug描述**
1.第一章""深度学习简介""中，“这样的思想后来被 PyTorch和MXNet的Gluon API 采用，后者也正是本书用来教学深度学习的工具。”，其中“后者”应该改为“前者”。
2.第二章""2.3.1""节中，建议将这句话去掉：“如果不想要被继续追踪，可以调用.detach()将其从追踪记录中分离出来，这样就可以防止将来的计算被追踪，这样梯度就传不过去了。” detach()会创建一个新的tensor，这新的tensor是从追踪记录中分离的，但是原tensor仍然会被追踪记录。对原tensor，要么直接修改.requires_grad为False，要么使用with torch.no_grad()包裹起来，使用detach()是无效的。
3.第二章""2.3.3""节中，""我么""改为""我们"".
"
Create deep learning of pytorch,studying pytorch
原书附录内容,"您好！
我翻译完了关于原书附录部分内容，请问是否可以添加进去？内容如下：
11.1 主要符号一览
11.2 数学基础
11.3 使用Jupyter记事本
11.4 使用AWS运行代码
11.5 GPU购买指南"
请问最后一章节《机器翻译》应该如何让它在 GPU 上运行呢？,请问最后一章节《机器翻译》应该如何让它在 GPU 上运行呢？
5.10 批量归一化,"**bug描述**
第一个epoch 没问题
第二个epoch, 出现如下问题：
Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.

修改loss.backward()为loss.backward(retain_graph)以后还是有问题
可能跟computation graph 有关？求解
还有人遇到么
**版本信息**
pytorch:
torchvision:
torchtext:
...
"
3.5节fashion-mnist.ipynb ModuleNotFoundError: No module named 'torchtext',"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等
3.5节fashion-mnist.ipynb
ModuleNotFoundError: No module named 'torchtext'

**版本信息**
pytorch:1.5
torchvision:0.6
torchtext:
...
"
文档2.3.3 梯度一节中最后一个例子，修改tensor.data不影响梯度吗？,"文档2.3.3节中例子：
```
x = torch.ones(1,requires_grad=True)

print(x.data) # 还是一个tensor
print(x.data.requires_grad) # 但是已经是独立于计算图之外

y = 2 * x
x.data *= 100 # 只改变了值，不会记录在计算图，所以不会影响梯度传播

y.backward()
print(x) # 更改data的值也会影响tensor的值
print(x.grad)
```
输出：
```
tensor([1.])
False
tensor([100.], requires_grad=True)
tensor([2.])
```
这里改变`x.data`没有改变到`x.grad`是因为`y=2*x`吧？
如果改成`y=x**2`：
```
x = torch.ones(1., requires_grad=True)
print(x.data)
print(x.data.requires_grad)

y = x ** 2
x.data *= 100
y.backward()
print(x)
print(x.grad)
```
输出变成了：
```
tensor([1.])
False
tensor([100.], requires_grad=True)
tensor([200.])  # 值改变了
```
文档中所述内容需要怎么理解呢？有点不太明白。"
函数get_fashion_mnist_labels(labels)调用时报错,"**bug描述**
def get_fashion_mnist_labels(labels):
    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
    return [text_labels[int(i)] for i in labels]
******
TypeError                                 Traceback (most recent call last)
<ipython-input-9-865ea1a418c8> in <module>
----> 1 get_fashion_mnist_labels(8)

<ipython-input-8-5a8c0c5ea81a> in get_fashion_mnist_labels(labels)
      2     text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
      3                    'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
----> 4     return [text_labels[int(i)] for i in labels]

TypeError: 'int' object is not iterable"
请问本书还会继续更新吗？,"原书英文版更新了生成对抗网络的内容，建议更新相关内容。感谢
"
5.12 DenseNet的实现,"**bug描述**
DenseNet中稠密连接的实现方式

**版本信息**
pytorch:
torchvision:
torchtext:
...
```python
def forward(self, X):
    for blk in self.net:
        Y = blk(X)
        X = torch.cat((X, Y), dim=1)  # 在通道维上将输入和输出连结
    return X
```
下面是torch官方的实现方法，我觉得这两者有些区别，下放这个更像是直观的稠密连接，features中的数值没有变过，书中的代码好像X的值一直在改变。（还是说，我理解错了）
```python
def forward(self,X):
    features = [X]
    for blk in self.net:
        Y = blk(torch.cat(features, dim=1))
        features.append(Y)
    return features
```"
继续请教前辈，ch5 vggnet 这里 x=blx（x）语法实在无法理解，谢谢前辈,"![blx](https://user-images.githubusercontent.com/41502003/79553476-1f4dcf00-80cf-11ea-9630-32580fd4c66c.png)
"
5.7   对于语法的疑惑   为什么blk前面会有一个星号呢    ,"![a](https://user-images.githubusercontent.com/41502003/79548222-b020ac80-80c7-11ea-9953-ecbe771306df.png)
"
错误很多啊，确认都跑通了？,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
3.6_softmax-regression-scratch 中运行train_ch3函数，显示叶子节点被移动到图内部,"**运行位置如下**
```
num_epochs, lr = 5, 0.1
def train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,
              params=None, lr=None, optimizer=None):
    for epoch in range(num_epochs):
        train_l_sum, train_acc_sum, n = 0.0, 0.0, 0
        for X, y in train_iter:
            y_hat = net(X)
            l = loss(y_hat, y).sum()

            # 梯度清零
            if optimizer is not None:
                optimizer.zero_grad()
            elif params is not None and params[0].grad is not None:
                for param in params:
                    param.grad.data.zero_()

            l.backward()
            if optimizer is None:
                d2l.sgd(params, lr, batch_size)
            else:
                optimizer.step()  # “softmax回归的简洁实现”一节将用到


            train_l_sum += l.item()
            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()
            n += y.shape[0]
        test_acc = evaluate_accuracy(test_iter, net)
        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'
              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))

train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)

```

**具体出现如下问题：**

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-16-066faa4268ff> in <module>()
     31               % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))
     32 
---> 33 train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)

<ipython-input-16-066faa4268ff> in train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr, optimizer)
     17 #                     param.grad.data.zero_()
     18 
---> 19             l.backward()
     20             if optimizer is None:
     21                 d2l.sgd(params, lr, batch_size)

/home/tpg/anaconda3/lib/python3.5/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    164                 products. Defaults to ``False``.
    165         """"""
--> 166         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    167 
    168     def register_hook(self, hook):

/home/tpg/anaconda3/lib/python3.5/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     97     Variable._execution_engine.run_backward(
     98         tensors, grad_tensors, retain_graph, create_graph,
---> 99         allow_unreachable=True)  # allow_unreachable flag
    100 
    101 

RuntimeError: leaf variable has been moved into the graph interior
```

**版本信息**
python: 3.5
pytorch:   1.3.1
torchvision:  0.4.2

 该函数前半部分的代码先自己手打了一遍，后出现该问题，于是直接将该文件下载下来，打开jupyter notebook运行，还是出现这个问题。

 按照报错的说法， 是叶子节点W， b被更改过了，尝试在代码片段中加入
```
print(params[0].is_leaf, params[1].is_leaf)
```
发现在第一次epoch时输出True, True. 但在第二次Epoch后两者都变为False，可见应该被更改过（变成非叶子节点），但无法排除具体在哪里发生错误。
"
参数更新时的batch_size，是否应该换成X_size，因为在抽取数据的情况下，batch_size的大小可能不够,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等

**版本信息**
![image](https://user-images.githubusercontent.com/42226555/78862104-1e7ec280-7a69-11ea-86cb-764c2447f73a.png)

pytorch:
torchvision:
torchtext:
...
"
3.11 欠拟合的图是不是有问题,"欠拟合的图里为什么泛化误差比训练误差要小？
![image](https://user-images.githubusercontent.com/30564738/78670068-d009e080-790f-11ea-9a17-c663a8ed2972.png)
我画出来和书上是相反的。"
9.1 图像增广 d2l.plt.imshow(img)报错,"[**bug描述**]

```
发生异常: NotImplementedError
Implement enable_gui in a subclass


 Traceback (most recent call last):
  File ""E:\anaconda\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""E:\anaconda\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""c:\Users\机械革命\.vscode\extensions\ms-python.python-2020.3.71659\pythonFiles\lib\python\debugpy\wheels\debugpy\__main__.py"", line 45, in <module>
    cli.main()
  File ""c:\Users\机械革命\.vscode\extensions\ms-python.python-2020.3.71659\pythonFiles\lib\python\debugpy\wheels\debugpy/..\debugpy\server\cli.py"", line 429, in main
    run()
  File ""c:\Users\机械革命\.vscode\extensions\ms-python.python-2020.3.71659\pythonFiles\lib\python\debugpy\wheels\debugpy/..\debugpy\server\cli.py"", line 266, in run_file
    runpy.run_path(options.target, run_name=compat.force_str(""__main__""))
  File ""E:\anaconda\lib\runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""E:\anaconda\lib\runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""E:\anaconda\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""c:\Users\机械革命\Desktop\PyTorch Code\PyTorch Train\PT29 Image Argumentation.py"", line 13, in <module>
    d2l.plt.imshow(img)
  File ""E:\anaconda\lib\site-packages\matplotlib\pyplot.py"", line 2677, in imshow
    __ret = gca().imshow(
  File ""E:\anaconda\lib\site-packages\matplotlib\pyplot.py"", line 926, in gca
    return gcf().gca(**kwargs)
  File ""E:\anaconda\lib\site-packages\matplotlib\pyplot.py"", line 603, in gcf
    return figure()
  File ""E:\anaconda\lib\site-packages\matplotlib\pyplot.py"", line 545, in figure
    **kwargs)
  File ""E:\anaconda\lib\site-packages\matplotlib\backend_bases.py"", line 3252, in new_figure_manager
    return cls.new_figure_manager_given_figure(num, fig)
    canvas = cls.FigureCanvas(figure)
  File ""E:\anaconda\lib\site-packages\matplotlib\backends\backend_qt5agg.py"", line 21, in __init__
    super().__init__(figure=figure)
  File ""E:\anaconda\lib\site-packages\matplotlib\backends\backend_qt5.py"", line 230, in __init__
    super().__init__(figure=figure)
  File ""E:\anaconda\lib\site-packages\matplotlib\backend_bases.py"", line 1582, in __init__
    self._fix_ipython_backend2gui()
  File ""E:\anaconda\lib\site-packages\matplotlib\backend_bases.py"", line 1629, in _fix_ipython_backend2gui
    ip.enable_matplotlib()
  File ""E:\anaconda\lib\site-packages\IPython\core\interactiveshell.py"", line 3419, in enable_matplotlib
    self.enable_gui(gui)
  File ""E:\anaconda\lib\site-packages\IPython\core\interactiveshell.py"", line 3378, in enable_gui
    raise NotImplementedError('Implement enable_gui in a subclass')
NotImplementedError: Implement enable_gui in a subclass

```
在import d2lzq_pytorch as d2l 之后
每次使用d2l.plt都会报错
希望大家能帮忙解决一下，谢谢

**版本信息**
pytorch: 1.4.0
torchvision:
torchtext:
...
"
是否考虑加入练习部分,"在原书中每个章节末尾，都附有练习一节。
思考练习的问题对加深理解比较有帮助，是否可以考虑后续加入这部分？"
3.2.2data_iter里面为什么用到循环,"**bug描述**
在3.2.2存在以下代码，我想知道为什么需要用到循环`for i in range(0, num_examples, batch_size)` 这里第一次循环结束就会返回结果了


```python
# 本函数已保存在d2lzh包中方便以后使用
def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    random.shuffle(indices)  # 样本的读取顺序是随机的
    for i in range(0, num_examples, batch_size):
        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # 最后一次可能不足一个batch
        yield  features.index_select(0, j), labels.index_select(0, j)
```"
10.12 机器翻译一节初始化Vocab,"10.12 机器翻译一节初始化Vocab中加入'\<unk\>',即:
vocab = torchtext.vocab.Vocab(collections.Counter(all_tokens), specials=['\<unk\>', PAD, BOS, EOS])
这样结果的词序索引与原书相同,最后预测不在词典里的词时也不会报错.
"
请问pytorch版本的《动手学深度学习》可以转为pdf吗,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
5.5节 train_ch5参数中的batch_size没有用上？,"**bug描述**
train_ch5参数中的batch_size没有用上。请问应该如何理解呢。
![image](https://user-images.githubusercontent.com/32954412/77548695-d77dc280-6ee9-11ea-882f-8e9c5e81ab75.png)

**版本信息**
pytorch: 1.2.0
torchvision: 0.4.0
torchtext: 0.4.0
windows10+Jupyter notebook
"
请问5.8节NiN网络中的1*1卷积核为什么用了好几个？,"请问5.8节NiN网络中的1x1卷积核为什么用了好几个？
文中说该网络用1x1的卷积层加全局平均池化层替代了全连接层以减少参数
但是为什么在前几层特征提取的时候也使用了1x1卷积层呢？
这对后续的非1x1卷积运算有什么好处吗？
求各位不吝赐教！"
9.9 语义分割和数据集过滤宽高顺序问题,"自定义语义分割数据集中过滤函数是否有误？
```   def filter(self, imgs):
        return [img for img in imgs if (
            img.size[1] >= self.crop_size[0] and
            img.size[0] >= self.crop_size[1])]
```
请问一下此处0、1顺序是否颠倒？"
6.4.1 one-hot向量,"**bug描述**
one-hot方法的测试代码的输入参数有误
![image](https://user-images.githubusercontent.com/34901333/76609556-89b0a400-6552-11ea-914f-9e5912cb629e.png)


**版本信息**
pytorch:1.1.0
torchvision:0.3.0
torchtext:0.5.1
"
9.4 锚框一节里的MultiBoxPrior方法,"MultiBoxPrior方法中的ss1赋值建议改为ss1 = pairs[:, 0] * pairs[:, 1] * h / w ,出来的结果与原书更贴切.
我修改过的MultiBoxPrior方法如下,经与mxnet的MultiBoxPrior测试比较,输出的结果类似:
def MultiBoxPrior(feature_map: torch.Tensor, sizes, ratios):
    pairs = []
    h, w = feature_map.shape[-2:]
    for s in sizes:
        pairs.append([s, math.sqrt(ratios[0])])
    for r in ratios[1:]:
        pairs.append([sizes[0], math.sqrt(r)])
    pairs = torch.tensor(pairs, device=feature_map.device)
    ss1 = pairs[:, 0] * pairs[:, 1] * h / w
    ss2 = pairs[:, 0] / pairs[:, 1]
    base_anchors = torch.stack([-ss1, -ss2, ss1, ss2], dim=1) / 2
    shifts_x = torch.arange(0, w, dtype=torch.float, device=feature_map.device) / w
    shifts_y = torch.arange(0, h, dtype=torch.float, device=feature_map.device) / h
    shift_y, shift_x = torch.meshgrid(shifts_y, shifts_x)
    shift_x = shift_x.reshape(-1)
    shift_y = shift_y.reshape(-1)
    shifts = torch.stack((shift_x, shift_y, shift_x, shift_y), dim=1)
    anchors = shifts.reshape((-1, 1, 4)) + base_anchors.reshape((1, -1, 4))
    offset_x, offset_y = 1.0 / w, 1.0 / h
    return anchors.view(1, -1, 4) + torch.tensor([offset_x / 2, offset_y / 2, offset_x / 2, offset_y / 2], device=feature_map.device)


"
9.2 微调一节中的热狗识别学习率问题,"原书中热狗识别学习率为0.01,考虑到mxnet里梯度递减里已经除了批次数(128),所以pytorch里应该为1e-4左右比较合适,经验证,如果学习率设的和原书mxnet里一样,则泛化误差很大,学习率为1e-4时,训练效果跟原书类似.

"
ImportError：d2lzh_pytorch中from IPython.display import set出错。,"**bug描述**
报错信息：
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-89-063794052f91> in <module>()
      1 sys.path.append('/content/gdrive/My Drive/Colab Notebooks/')
----> 2 import d2lzh_pytorch as d2l

1 frames
/content/gdrive/My Drive/Colab Notebooks/d2lzh_pytorch/__init__.py in <module>()
----> 1 from .utils import *
      2 

/content/gdrive/My Drive/Colab Notebooks/d2lzh_pytorch/utils.py in <module>()
     11 from PIL import Image
     12 from collections import namedtuple
---> 13 from IPython.display import set
     14 from IPython import display
     15 from matplotlib import pyplot as plt

ImportError: cannot import name 'set'

---------------------------------------------------------------------------

在`IPython.display`中没有`set`函数。
删掉d2lzh_pytorch中的`from IPython.display import set`即可。

**版本信息**
pytorch:1.4.0
torchvision:0.3.1
torchtext:0.3.1
IPython:5.5.0
..."
5.9.2-GoogLeNet模型,"**bug描述**
5.9.2GoogLeNet模型--b2模块中，两个卷积层后没有跟激活函数ReLU()，原书代码是有的
![image](https://user-images.githubusercontent.com/34901333/76133949-f52bda80-6055-11ea-99bc-fe171b54a200.png)

**版本信息**
pytorch:1.1.0
torchvision:0.3.0
torchtext:0.5.1
"
fcn更新,"fcn更新
"
关于第九章目标检测的三个函数实现,"  你好，我按照李沐原书里的代码实现了9.6节SSD的神经网络来进行目标检测，在其中需要用到MultiBoxPrior、MultiBoxTarget、MultiBoxDetection这三个作者实现的函数。但是似乎MultiBoxDetection的实现有一点问题。
  书中我看到MultiBoxTarget在输入锚框和真实目标框之后，会输出每个锚框根据其所在类别相较于真实框的位置偏移bbox_offset,在书中例子给出来的输出结果中，有些坐标的偏移达到了7.17、10这个数量级(李沐的原书里面也是这样)，然后我看到作者在后续的MultiBoxDetection实现上好像直接把这个偏移加到了锚框坐标上？这样的话加上很大数量级的偏移得到的锚框位置甚至会跑出图像，所以我是用以上三个函数及我训练的神经网络进行目标预测得到的目标框有很多会飘出图像内，可能是MXNET的实现中做了一些调整？"
6.5 循环神经网络的简洁实现中调用梯度裁剪grad_clipping问题,"6.5 循环神经网络的简洁实现中调用梯度裁剪方法:
d2l.grad_clipping(model.parameters(), clipping_theta, device)
传入的model.parameters()是迭代器,在grad_clipping方法里的第一次for循环迭代中已迭代完,在第二次for循环迭代中不会重新迭代.
def grad_clipping(params, theta, device):
    norm = torch.tensor([0.0], device=device)
    for param in params: ###  # 第一次循环迭代, 将params迭代完
        norm += (param.grad.data ** 2).sum()
    norm = norm.sqrt().item()
    if norm > theta:
        for param in params:  # params已迭代完,不会重新开始,无法再进入后面的赋值
            param.grad.data *= (theta / norm)

应改为d2l.grad_clipping(list(model.parameters()), clipping_theta, device)"
代码讲解视频分享,"Hi~ 非常感谢作者开源了那么优质的项目！
上交的志愿者团队参考了你的代码、补全了未完成的部分并且录制了代码讲解视频，同样是免费开放的！
https://www.boyuai.com/elites/course/cZu18YmweLv10OeV
作者考虑加到repo的readme里吗！
"
请问第五章的lenet和alaxnet网络中转为全连接层时的4x4和5x5是怎么算出来的,"请问第五章的lenet和alaxnet网络中专为全连接层时的4x4和5x5是怎么算出来的？
LeNet
 nn.Linear(16*4*4, 120),
AlexNet
nn.Linear(256*5*5, 4096),"
3.6.7章节运行train_ch3函数报错,"**bug描述**
`num_epochs, lr = 5, 0.1`
`d2l.train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)`

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-36-37f0219b21d5> in <module>
      2 
      3 
----> 4 d2l.train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, batch_size, [W, b], lr)

~\动手深度学习\d2lzh_pytorch\utils.py in train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr, optimizer)
    132                     param.grad.data.zero_()
    133 
--> 134             l.backward()
    135             if optimizer is None:
    136                 sgd(params, lr, batch_size)

C:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\tensor.py in backward(self, gradient, retain_graph, create_graph)
    193                 products. Defaults to ``False``.
    194         """"""
--> 195         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    196 
    197     def register_hook(self, hook):

C:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\autograd\__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     97     Variable._execution_engine.run_backward(
     98         tensors, grad_tensors, retain_graph, create_graph,
---> 99         allow_unreachable=True)  # allow_unreachable flag
    100 
    101 

RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn

**版本信息**
pytorch:
torchvision:1.4.0
torchtext:
...
"
3.16中的rmse的损失计算,"**bug描述**
 rmse = torch.sqrt(2 * loss(clipped_preds.log(), labels.log()).mean())
根据公式可以理解，loss()函数是计算MSE，求平均也好理解，为什么要乘以2，求解答，感谢~

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
7.8.3 Gluon 未替换为 PyTorch,"**bug描述**

7.8.3 Gluon 未替换为 PyTorch

> 我们便可使用Gluon提供的Adam算法。

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
关于3.5和3.5节中的问题,"**bug描述**
3.5节，为啥我下的数据集显示大小是60000，60000, 原文是60000, 10000


3.6节，原文说测试集的准确率应该接近1/10，但是我这里是0.000413671875
**版本信息**
pytorch:1.4.0
torchvision:0.5.0
torchtext:0.5.0
...
"
网页版和之前不一样了,"**bug描述**

今天打开网页版，目录变了，文中公式出现了很多undefined

"
4.5.1 load拼写错误,"**bug描述**

load拼写错误 为 laod

> 而laod使用pickle unpickle工具将pickle的对象文件反序列化为内存。

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
3.13.2.2 is_training 描述错误,"is_training 是示例函数的bool类型参数而非函数

> 我们可以通过参数is_training函数来判断运行模式为训练还是测试，并只需在训练模式下使用丢弃法。

```python
drop_prob1, drop_prob2 = 0.2, 0.5

def net(X, is_training=True):
    X = X.view(-1, num_inputs)
```"
non_max_suppression 函数 死循环,"**bug描述**

9.4节代码的non_max_suppression函数，存在死循环。
```python
while len(sorted_bb_info_list) != 0:
```
这个条件可以无法退出。

**版本信息**
pytorch:1.3.1
torchvision:0.4.2
torchtext:0.4.0
...
"
皮卡丘的数据集,"![image](https://user-images.githubusercontent.com/42534375/72236598-9415f680-3612-11ea-84be-0f8d393a886f.png)
网站点进去是这样的，另外代码里面跑一直卡在下面那张图里不动
![image](https://user-images.githubusercontent.com/42534375/72236635-b60f7900-3612-11ea-8fd6-a887b8155b1d.png)
是我网络的问题吗？还是有其他解决的办法，谢谢大佬~"
word2vec章节二次采样处感觉弄错了吧,"**bug描述**
word2vec章节二次采样处感觉弄错了吧
```
def discard(idx):
 return random.uniform(0, 1) < 1 - math.sqrt(1e-4 / counter[idx_to_token[idx]] * num_tokens)
```
是不是改改成
```
    return random.uniform(0, 1) < 1-math.sqrt(t/(counter[idx_to_token[idx]]/num_tokens))
```

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
gru章节代码是否有误,"gru 在定义模型函数里
```
H_tilda = torch.tanh(torch.matmul(X, W_xh) + R *torch.matmul(H, W_hh) + b_h)
```
应该改成：
```
H_tilda = torch.tanh(torch.matmul(X, W_xh) + torch.matmul((R*H), W_hh) + b_h)
```
"
2.3节关于grad_fn的测试代码在PyTorch 1.3.1中运行结果与说明不符,"**bug描述**
grad_fn的测试代码在PyTorch 1.3.1中运行结果与说明不符

``` python
y = x + 2
...
print(y.grad_fn) #output None
```
2.3.3小节第一段代码运行报错
``` python
out.backward() # 等价于 out.backward(torch.tensor(1.))
print(x.grad)
```
``` bash
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-23-5b0e34440c47> in <module>
----> 1 out.backward() # 等价于 out.backward(torch.tensor(1.))
      2 print(x.grad)

/mnt/e/Programs/SageMath/local/lib/python3.7/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    164                 products. Defaults to ``False``.
    165         """"""
--> 166         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    167 
    168     def register_hook(self, hook):

/mnt/e/Programs/SageMath/local/lib/python3.7/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
     97     Variable._execution_engine.run_backward(
     98         tensors, grad_tensors, retain_graph, create_graph,
---> 99         allow_unreachable=True)  # allow_unreachable flag
    100 
    101 

RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
```

**版本信息**
pytorch:1.3.1+cpu
...
"
111,111
章节2.2 数据操作,"**bug描述**
章节2.2中，我在使用x.view()时，然后在修改x中的值，并未看到数据共享的情况，
![image](https://user-images.githubusercontent.com/19511703/71805065-2c0a6200-30a0-11ea-923c-10957a8c3c30.png)

![image](https://user-images.githubusercontent.com/19511703/71805030-17c66500-30a0-11ea-8785-8b3ba68584d3.png)


**版本信息**
pytorch: 1.1.0
torchvision:0.3.0
torchtext:未安装
...
"
勘误个无关紧要的希望项目越来越好,"![微信图片_20200102195944](https://user-images.githubusercontent.com/58239273/71666097-72a74600-2d9a-11ea-9732-579f698a9760.png)
情感分析RNN里面的
oov_count += 0 应该是 oov_count += 1
下面输出语句忘了加 %oov_count了"
3.3 节最后的损失函数需要sum后才可以调用backward函数,3.3.7 训练模型：损失函数需要sum
您好，在章节3.7中有个疑惑,"章节3.7中，3.7.2，您写到是“在3.4节(softmax回归)中提到，softmax回归的输出层是一个全连接层，所以我们用一个线性模块就可以了”。在后面的实现中，您也是用了一个nn.Linear()，但是softmax一个重要的地方是将输出值变换成值为正且和为1，但是我没有在3.7的代码里找到呀，是不是不能称之为softmax回归了呢？
"
Create 动手学深度学习,
3.2.2读取数据一节 调用data_iter时报错提示对象不可迭代,"因为是小白，这里的bug迟迟无法解决，还望各位大佬不吝赐教啊。
（1）问题：
执行这段代码：
batch_size = 10
for X, y in data_iter(batch_size, features, labels):
    print(X, '\n', y)
    break
（2）报错：
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-82-f5efc5a58268> in <module>()
      1 batch_size = 10
      2 
----> 3 for X, y in data_iter(batch_size, features, labels):
      4     print(X, '\n', y)
      5     break

TypeError: 'NoneType' object is not iterable
"
第5章第8节NiN网络中的函数(NameError: name 'F' is not defined),"class GlobalAvgPool2d(nn.Module):
    # 全局平均池化层可通过将池化窗口形状设置成输入的高和宽实现
    def __init__(self):
        super(GlobalAvgPool2d, self).__init__()
    def forward(self, x):
        return F.avg_pool2d(x, kernel_size=x.size()[2:])

使用这个类的时候一直显示F.is not defined.直接从d2lzh_pytorch中调用也是显示F.is not defined
想请问一下是我自己的问题还是代码的问题？谢谢~"
本项目网页版章节目录错别字,"“食用方法”应该是使用方法
"
如何认领翻译章节,是否可认领未翻译章节？烦请添加Contribution Guidelines
3.5节fashion-mnist.ipynb下载FashionMNIST数据集报错,"python 3.6.7
pytorch 1.1
torchvision 0.3

这一行报错
mnist_train = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=True, download=True, transform=transforms.ToTensor())

0it [00:00, ?it/s]
Using downloaded and verified file: /home/zhoushijie/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz
Extracting /home/zhoushijie/Datasets/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /home/zhoushijie/Datasets/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz
---------------------------------------------------------------------------
ZeroDivisionError                         Traceback (most recent call last)
<ipython-input-2-11bc6d04d2d5> in <module>
----> 1 mnist_train = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=True, download=True, transform=transforms.ToTensor())
      2 mnist_test = torchvision.datasets.FashionMNIST(root='~/Datasets/FashionMNIST', train=False, download=True, transform=transforms.ToTensor())

~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torchvision/datasets/mnist.py in __init__(self, root, train, transform, target_transform, download)
     66 
     67         if download:
---> 68             self.download()
     69 
     70         if not self._check_exists():

~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torchvision/datasets/mnist.py in download(self)
    143             filename = url.rpartition('/')[2]
    144             file_path = os.path.join(self.raw_folder, filename)
--> 145             download_url(url, root=self.raw_folder, filename=filename, md5=None)
    146             self.extract_gzip(gzip_path=file_path, remove_finished=True)
    147 

~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torchvision/datasets/utils.py in download_url(url, root, filename, md5)
     78             urllib.request.urlretrieve(
     79                 url, fpath,
---> 80                 reporthook=gen_bar_updater()
     81             )
     82         except OSError:

~/anaconda3/envs/pytorch/lib/python3.6/urllib/request.py in urlretrieve(url, filename, reporthook, data)
    272 
    273             if reporthook:
--> 274                 reporthook(blocknum, bs, size)
    275 
    276             while True:

~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torchvision/datasets/utils.py in bar_update(count, block_size, total_size)
     13             pbar.total = total_size
     14         progress_bytes = count * block_size
---> 15         pbar.update(progress_bytes - pbar.n)
     16 
     17     return bar_update

~/anaconda3/envs/pytorch/lib/python3.6/site-packages/tqdm-4.7.2-py3.6.egg/tqdm/_tqdm.py in update(self, n)
    687                 if self.smoothing and delta_t:
    688                     self.avg_time = delta_t / delta_it \
--> 689                         if self.avg_time is None \
    690                         else self.smoothing * delta_t / delta_it + \
    691                         (1 - self.smoothing) * self.avg_time

ZeroDivisionError: float division by zero"
自定义的sgd函数中的“除以batch_size”是否要省略需要视loss如何定义,"**bug描述**
```
def sgd(params, lr, batch_size):
    # 为了和原书保持一致，这里除以了batch_size，但是应该是不用除的，因为一般用PyTorch计算loss时就默认已经沿batch维求了平均了。除batch size后训练速度变慢
    for param in params:
        param.data -= lr * param.grad #/ batch_size
```
首先说batch_size需要除就必须除，不能除就必须不除，没有应该不应该。

loss的定义如果是如3.7节中调用nn.CrossEntropyLoss()，是**不能**除以batch_size的，原因如源码所述，CrossEntropyLoss()已经沿batch_size取了平均。
而如果loss是采用3.6节中自定义的cross_entropy函数，而且在训练时l = loss(y_hat, y).sum()（计算的是批量样本loss和，不是平均），那在sgd中**必须**要除以batch_size，而如果定义l = loss(y_hat,     y).sum()/batch_size，效果跟调用nn.CrossEntropyLoss()是相同的，此时sgd就**不能**再除以batch_size了。

这里定义loss的方式不同，带来的另一个问题是每一个epoch结束后计算平均loss的方式，如#74 所述，如果loss的定义是3.7节中调用nn.CrossEntropyLoss()，在print loss时，应该是train_loss_sum/len(train_iter)，而如果l = loss(y_hat, y).sum()，才是train_loss_sum/n

**版本信息**
pytorch:1.3.1
torchvision:0.4.2
torchtext:0.4.0
...
"
loss计算错误,"**bug描述**
3.7 3.9中计算交叉熵损失函数时使用tf.nn.CrossEntropyLoss()时，已经作了平均。
但是计算每一个epoch的损失时，又除了整个训练集样本的个数n ，这样对吗？ 

**版本信息**
pytorch:1.13
torchvision:0.4.2
torchtext:无
...
"
Chapter 2.3.2 梯度 - 变量描述错误,"**bug描述**
Chapter 2.3.2 梯度

![image](https://user-images.githubusercontent.com/38641789/70679580-864a1a00-1cd0-11ea-9602-02c2b9b53b4e.png)


**版本信息**
pytorch:
torchvision:
torchtext:
...
"
书中seq2seq + Attention部分有一些代码是基于size间相等的前提写的，which is not always true.,"
![image](https://user-images.githubusercontent.com/47956194/70623786-cb7f3500-1c59-11ea-9aa0-9fc3f18efc3e.png)

比如这个attention前向传播的代码，这里是默认encoder_hidden_size == decoder_hidden_size，所以下面红线处input_size 才能用2倍num_hiddens来赋值，并且上面红线处才可以直接dec_state.expand_as(enc_state)。

![image](https://user-images.githubusercontent.com/47956194/70624032-5102e500-1c5a-11ea-9c89-a36383ce7779.png)
这边又默认了hidden_size == embedding_size，所以decoder中的input_size 才能用2倍embedding_size来赋值。

我感觉这里是不是写的更具有普遍性会比较好，否则容易误导读者，我一开始就纳闷了很久为什么是*2。


"
docs文件夹下第二章的2.3节的文件讲梯度哪里好像显示出来有点问题,"梯度哪里有一堆类似如下的符号：
数学上，如果有一个函数值和自变量都为向量的函数 $\vec{y}=f(\vec{x})$, 那么 $\vec{y}$ 关于 $\vec{x}$ 的梯度就是一个雅可比矩阵（Jacobian matrix）:
$$
J=\left(\begin{array}{ccc}
   \frac{\partial y_{1}}{\partial x_{1}} & \cdots & \frac{\partial y_{1}}{\partial x_{n}}\\
   \vdots & \ddots & \vdots\\
   \frac{\partial y_{m}}{\partial x_{1}} & \cdots & \frac{\partial y_{m}}{\partial x_{n}}
   \end{array}\right)

看不太懂，可否修正一下？
"
No module named 'd2lzh_pytorch',"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等
我在3.10 节中引入 d2lzh_pytorch 这个包后总是报错，说我没有这个包，我想问问这个包应该是在哪里安装的，我查了没查到，谢谢作者解答
**版本信息**
pytorch:  1.3.1
torchvision: 0.4.2
torchtext:  0.4.0
...
"
AttributeError: module 'd2lzh_pytorch' has no attribute 'load_data_fashion_mnist',"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
5.10使用pandoc转为pdf报错,"**bug描述**
chapter05中的5.10_batch-norm.md文件，转为pdf的时候报错。信息如下：

Error producing PDF.
! Missing { inserted.
<to be read again> 
                   \__um_group_begin: 
l.135 \[\boldsymbol{\mu}_\mathcal

对markdown和LaTeX的语法不熟，不知道是什么原因？其他的章节都没问题。

谢谢
**版本信息**
pytorch:
torchvision:
torchtext:
...
"
4.2.2常数初始化偏置参数吧,"
"
应该是我的问题……,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等

**版本信息**
pytorch:3.7
torchvision:1.2.0
torchtext:0.4.0
...
![image](https://user-images.githubusercontent.com/24327390/69720437-964cf000-114d-11ea-85bc-cbae437fcc66.png)
set函数去重之后，后面的
![image](https://user-images.githubusercontent.com/24327390/69720522-c5636180-114d-11ea-8613-0c977e02c4cd.png)
idx_to_char访问会越界"
rnn-pytorch中循环神经网络那张图下面的输出形状是否有误?,"![1574817355(1)](https://user-images.githubusercontent.com/58239273/69685259-c6b56f80-10f6-11ea-8f0c-baa7df7594c5.jpg)
输出形状是否应该为（时间步数，批量大小，隐藏层单元个数）。"
Update 10.12_machine-translation.md,
丢弃法的 dropout 函数有误,"好吧，发现是我看了旧版本。

**bug描述**
丢弃法的 dropout 函数使用的 torch.randn 是正态分布，这样的话就不是精确按指定概率丢弃了，应该用平均分布。
![image](https://user-images.githubusercontent.com/3375942/69476749-ef004e00-0e18-11ea-8c46-40ea8be8dc03.png)


**版本信息**
算法错误，跟版本无关
"
报错，核心已转储,"**bug描述**
3.6节运行时出错，猜测与“import d2lzh_pytorch as d2l”有关。
下面是具体bug信息:
bash: 行 1: 12013 段错误               (核心已转储) env ""PYCHARM_HOSTED""=""1"" ""PYTHONUNBUFFERED""=""1"" ""PYTHONIOENCODING""=""UTF-8"" ""PYCHARM_MATPLOTLIB_PORT""=""49946"" ""JETBRAINS_REMOTE_RUN""=""1"" ""PYTHONPATH""=""/home/zjr/pytorch:/home/zjr/pytorch/SR-GNN-master/pytorch_code:/home/zjr/.pycharm_helpers/pycharm_matplotlib_backend"" '/home/zjr/anaconda3/envs/pytorch/bin/python3.6' '-u' '/home/zjr/pytorch/pytorch-pretrain/3.6_simple.py'

**版本信息**
pytorch:1.2.0
torchvision:0.4.0
torchtext:0.3.1
...
"
修复size mismatch问题,LeNet 卷积最后的结果为 `16@5x5` 的 tensor ，所以这里应该是 `16x5x5`
关于第五章的函数 d2l.train_ch5 ,"**bug描述**
关于第五章的函数 d2l.train_ch5 中的batch_count=0难道不应该写在循环内部吗，请问老师您为什么把问题关掉了，不太理解，所以再来询问一下。

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
10.7.1.3文本情感分类章节，数据迭代器提示错误,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等
在创建数据迭代器的时候报错，没有错误提示，显示的是某一个单词卡住，之前以为是代码写错了，但是在运行了课本提供的代码后依然有这个错误问题。
![image](https://user-images.githubusercontent.com/4464168/68663153-28170380-0579-11ea-8f03-6a8ff302b09b.png)



**版本信息**
pytorch:1.0.0
torchvision:
torchtext:0.4.0
...
"
5.10.2 「从零开始实现批量归一化」 的实现可以优化,"**bug描述**
文中是这样写的：
```
mean = X.mean(dim=0, keepdim=True).mean(dim=2, keepdim=True).mean(dim=3, keepdim=True)
```
而原文是这样的：
```
mean = X.mean(axis=(0, 2, 3), keepdims=True)
```
事实上，pytorch 也支持类似写法，如下：
```
mean = X.mean(dim=(0, 2, 3), keepdim=True)
```
这种写法除了简洁外，数值上应该更精确一些。
**版本信息**
pytorch: 1.3.1
...
"
第五章的函数 d2l.train_ch5 中的batch_count应该写在循环内部,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等
如题

**版本信息**
pytorch:1.2
torchvision:
torchtext:
...
"
Fix a typo of pytorch indexing function,
关于2.3_autograd.md中修改tensor.data的值不会影响反向传播,"修改tensor.data的值不会影响反向传播，有点不太懂？
如果y=x^2，此时修改x.data的值，会影响x.grad的值，不知道这个地方怎么理解？
![image](https://user-images.githubusercontent.com/9025284/67764448-f421e580-fa84-11e9-8e1f-ccbdb0fca407.png)
![image](https://user-images.githubusercontent.com/9025284/67764525-259ab100-fa85-11e9-9d62-034d4b79e2f8.png)
"
3.2节里的线性回归w和b的初始化时数据为float32类型，导致后面计算矩阵相乘错误,"python vision:py3.7
torchvision：0.4.0

3.2节里的线性回归w和b的初始化时数据为float32类型，导致后面计算矩阵相乘错误
我试着打印出features时，发现数据类型是float64类型的，而后面的w和b均是float32类型。训练的时候使用torch.mm做矩阵，这个函数需要统一传进来的三个参数类型，所以在初始化w和b时需要将其设置为torch.float64类型才可以。

验证如下：
![LUN_JV9XPNS9 1){_300 $8](https://user-images.githubusercontent.com/26972500/67628644-114b8e00-f8a4-11e9-9d5a-968304371382.png)
![error](https://user-images.githubusercontent.com/26972500/67628633-dd706880-f8a3-11e9-83f0-2d991add287f.png)


修改后的结果如下：
![1572143875(1)](https://user-images.githubusercontent.com/26972500/67628747-e95d2a00-f8a5-11e9-8ee3-06eef888a646.jpg)
![4(V6YZBV@`QXJ%E6OD}0LVI](https://user-images.githubusercontent.com/26972500/67628752-f8dc7300-f8a5-11e9-8caa-3d1cd6299a13.png)
"
关于word2vec我有一个问题就是，我看李沐的视频，他说每个词有两个向量表示，一个是作为中心词时候的向量表示，一个是作为背景词时候的向量表示。在训练的时候这一点要怎么表现出来呢？,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
update 4.1_model-construction.md,
fix 3.10_mlp-pytorch.md,
fix 3.5_fashion-mnist.md,
fix 3.5_fashion-mnist.md,
The pictures of formulas in this book are not visible! ,"![1571822380(1)](https://user-images.githubusercontent.com/35477838/67378148-62fccb80-f5b9-11e9-976a-63d9ed3e5194.jpg)

The pictures of formulas in this book are not visible! It's very inconvenient for readers to read.
"
Update 2.1_install.md,修改打字错误
3.16节 kaggle_house的一个小错误,"**bug描述**
在预处理数据代码中，原文为
all_features[numeric_features] = all_features[numeric_features].fillna(0) 
最终输出应为 all_features.shape = (2919, 331)
而在您编写的代码中，此句变为
all_features = all_features.fillna(0)
最终输出为all_features.shape = (2919, 354)，
初次接触pandas，不知这个是您的疏忽还是由于我对代码的理解不充分，望解答，十分感谢。

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
运行实验深度卷积神经网络的时候直接把我c盘干满了，咋回事啊,"**bug描述**
描述一下你遇到的bug, 例如报错位置、报错信息（重要, 可以直接截个图）等

**版本信息**
pytorch:
torchvision:
torchtext:
...
"
建议将项目简介里的链接换为https的,
建议增加CI/CD,"可以在CI里边做静态网页生成和pdf生成，在CD里边部署网页，这样就可以只专注于markdown及图片的修改。

看了下，作者似乎是想放到github pages上，[travis-ci 也有相应的支持](https://docs.travis-ci.com/user/deployment/pages/)。
"
fix typo,
Update 2.3_autograd.ipynb ,"Change `tensor.data` to `tensor.detach()` due to
https://github.com/pytorch/pytorch/issues/6990#issuecomment-384680164
`tensor.detach()` is more robust than `tensor.data`. "
4.2.2 未针对PyTorch修改,
Chapter3.16字误、排版微调,"修改内容如下：
* 3.15章增加图3.8图片显示，方便理解
* 3.16字误修改，内容安排更合理化一些

:))"
Chapter3.10 3.13,"修改如下：

1. `torch.randn(X.shape)`  -> `torch.randn(X.shape).uniform_(0, 1)`，满足uniform方式生成
2. 增加`dropout(X, 0)`，`dropout(X, 0.5)`，以及`dropout(X, 1.0)`真实输出结果等，方便直观感受
3. **3.10**，以及**3.13**章节等细节调整等"
awk模式匹配在MacOS的兼容性调整，以及若干细微修改,"修复对应Issues #34 

:))"
Update 4.1_model-construction.md,
fix bugs,"1. 将MXNet的Gluon 修改为 PyTorch
2. 文档内容排版有误，输出结果与图片应在“模型选择”标题下
3. 前9个样本 -> 前10个样本"
《动手学深度学习》(PyTorch版)本地WEB访问打开姿势,"针对使用Mac/Linux等终端（不支持Windows）各位，可以快速本地以web方式访问《动手学深度学习》(PyTorch版)项目。

> 这不是一个 `Issue`，目的想让大家本地阅读本文档时更为舒服一些 :))
> 管理员可随时关闭掉......

## 快速体验

- `git clone https://github.com/ShusenTang/Dive-into-DL-PyTorch.git`
- 终端下执行`make wwwdocs`命令

```bash
# cd Dive-into-DL-PyTorch
# make wwwdocs
bash script/prepare_wwwdocs.sh
本脚本将自动创建 .wwwdocs 目录
初始化项目依赖时将使用 docsify 工具自动生成本地文档web访问文档
本web文档为绿色创建，不会对现有项目产生副作用！不会产生产生git需要提交文件！
请放心食用 :))
根据项目README.md自动生成目录文件 ......
根据项目根目录下README.md以及docs/README.md合并生成项目所需${docs}导航 ......
生成 docsify 所需入口文件......
为各章节markdown文件以及图片建立软连接 ......
启动web server，稍后请在浏览器中打开：http://localhost:3000 ，即可访问 ......

Serving /Users/nieyong/ai/book/Dive-into-DL-PyTorch/.wwwdocs now.
Listening at http://localhost:3000
```
- 在本地浏览器访问 `http://127.0.0.1:3000/` 即可完整显示所有数学公式了

## 截图展示

启动成功之后，请在chrome等现代浏览器内访问：`http://localhost:3000` 即可。

来一个首页和导航标签显示：
![](https://i.loli.net/2019/10/18/qgYNKEjU58bRmAl.png)

内置JS完整支持数学公式显示（不再需要在Chrome上安装任何插件）：
![](https://i.loli.net/2019/10/18/6aYdmnpVXMWbNke.png)

代码显示增加拷贝支持：
![](https://i.loli.net/2019/10/18/qMfBhDoHpIEFer2.png)

增加搜索支持：
![](https://i.loli.net/2019/10/18/NnV7zxZKPyi6fHr.png)

![](https://i.loli.net/2019/10/18/cnkldsQfwFJpeDE.png)

## 其它

本方案非常绿色：

- 完全不会对现有项目造成侵入
- 经常执行`git fetch ; git rebase`命令即可更新上游文档内容
    - 完全不用重新构建！
    - `http://127.0.0.1:3000/` 会实时刷新等

希望能给各位带来一点帮助 :))"
Update 3.5_fashion-mnist.md,有10个样本 😉 
【建议：】可通过gitbook搭建在线书籍,示例：https://zooltd.gitbook.io/dive-into-deep-learning-demo/
3.2.7训练模型 代码bug,"**bug描述**
3.2.7训练模型 代码运行报错

RuntimeError                              Traceback (most recent call last)
<ipython-input-36-7b29f0453e1a> in <module>
      8     # 和y分别是小批量样本的特征和标签
      9     for X, y in data_iter(batch_size, features, labels):
---> 10         l = loss(net(X, w, b), y).sum()  # l是有关小批量X和y的损失
     11         l.backward()  # 小批量的损失对模型参数求梯度
     12         sgd([w, b], lr, batch_size)  # 使用小批量随机梯度下降迭代模型参数

<ipython-input-33-7aefd52381cf> in linreg(X, w, b)
      1 def linreg(X, w, b):  # 本函数已保存在d2lzh_pytorch包中方便以后使用
----> 2     return torch.mm(X, w) + b

RuntimeError: Expected object of scalar type Double but got scalar type Float for argument #2 'mat2'

将3.2.3初始化参数部分类型改为double或float64可运行


**版本信息**
pytorch:1.2.0
torchvision:0.4.0
torchtext:?
安装指令是
conda install pytorch torchvision cudatoolkit=10.0
使用清华镜像
"
3.7_softmax-regression-pytorch.ipynb中运行d2l.train_ch3()报错,"**bug描述**
运行d2l.train_ch3()报错
报错位置:
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)
报错信息:
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-10-4f5dfa17aa83> in <module>
      1 num_epochs = 5
----> 2 d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)

D:\Users\Administrator\Anaconda3\Dive-into-DL-PyTorch-master\code\d2lzh_pytorch\utils.py in train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr, optimizer)
    140             train_acc_sum += (y_hat.argmax(dim=1) == y).sum().item()
    141             n += y.shape[0]
--> 142         test_acc = evaluate_accuracy(test_iter, net)
    143         print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f'
    144               % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc))

D:\Users\Administrator\Anaconda3\Dive-into-DL-PyTorch-master\code\d2lzh_pytorch\utils.py in evaluate_accuracy(data_iter, net, device)
    212             if isinstance(net, torch.nn.Module):
    213                 net.eval() # 评估模式, 这会关闭dropout
--> 214                 acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()
    215                 net.train() # 改回训练模式
    216             else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU

d:\program files\python36\lib\site-packages\torch\nn\modules\module.py in __call__(self, *input, **kwargs)
    539             result = self._slow_forward(*input, **kwargs)
    540         else:
--> 541             result = self.forward(*input, **kwargs)
    542         for hook in self._forward_hooks.values():
    543             hook_result = hook(self, input, result)

d:\program files\python36\lib\site-packages\torch\nn\modules\container.py in forward(self, input)
     90     def forward(self, input):
     91         for module in self._modules.values():
---> 92             input = module(input)
     93         return input
     94 

d:\program files\python36\lib\site-packages\torch\nn\modules\module.py in __call__(self, *input, **kwargs)
    539             result = self._slow_forward(*input, **kwargs)
    540         else:
--> 541             result = self.forward(*input, **kwargs)
    542         for hook in self._forward_hooks.values():
    543             hook_result = hook(self, input, result)

d:\program files\python36\lib\site-packages\torch\nn\modules\linear.py in forward(self, input)
     85 
     86     def forward(self, input):
---> 87         return F.linear(input, self.weight, self.bias)
     88 
     89     def extra_repr(self):

d:\program files\python36\lib\site-packages\torch\nn\functional.py in linear(input, weight, bias)
   1368     if input.dim() == 2 and bias is not None:
   1369         # fused op is marginally faster
-> 1370         ret = torch.addmm(bias, input, weight.t())
   1371     else:
   1372         output = input.matmul(weight.t())

RuntimeError: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_addmm

**版本信息**
pytorch: 1.3.0
torchvision: 0.4.1
torchtext: 0.4.0
...
"
在本地上运动我该怎么导入d2lzh_pytorch ,求解
fix lenet5 wrong Linear layer,"和英文版的以及原论文的比对了一下，确定这里的输入参数算错了。
https://github.com/dsgiitr/d2l-pytorch/blob/master/Ch08_Convolutional_Neural_Networks/Convolutional_Neural_Networks(LeNet).ipynb"
增加项目文档库本地web浏览支持,"这是最新的PR提交，修复前面已被我关闭PR #25 存在的客户端MathJax显示方面BUG。

:))"
如果使用pytorch1.1.0版本，章节3.7和3.10的代码会无法运行,
增加项目docs目录本地web浏览支持,"## 说明

本次提交为项目增加项目markdown文件自动转换为web文档访问方式。

机制如下:

- 借助于 `docsify` 工具自动为当前项目`docs`目录生成本地web文档访问方式
- 使用bash script脚本自动生成 `docsify` 工具所需目录，以及数学公式支持等
- 本次提交，以优先在浏览器端显示数学公式为首要任务，可能会导致其它细节暂时没空注意到

## 如何使用

在Mac/Linux等终端下（不支持Windows），进入项目目录，输入 `make wwwdocs`，然后回车即可。

```bash
# make wwwdocs
bash script/prepare_wwwdocs.sh
本脚本将自动创建 .wwwdocs 目录
初始化项目依赖时将使用 docsify 工具自动生成本地文档web访问文档
本web文档为绿色创建，不会对现有项目产生副作用！不会产生产生git需要提交文件！
请放心食用 :))
根据项目README.md自动生成目录文件 ......
根据项目根目录下README.md以及docs/README.md合并生成项目所需${docs}导航 ......
生成 docsify 所需入口文件......
为各章节markdown文件以及图片建立软连接 ......
启动web server，稍后请在浏览器中打开：http://localhost:3000 ，即可访问 ......

Serving /Users/nieyong/ai/book/Dive-into-DL-PyTorch/.wwwdocs now.
Listening at http://localhost:3000
```

启动成功之后，请在chrome等现代浏览器内访问：`http://localhost:3000` 即可。

效果截图如下:

![](https://i.loli.net/2019/10/11/QTiqz5j8K1YsxmN.jpg)


## 其它

介于本人能力、精力有限（另作为Pytorch的初学者连门都还没入呢），并未展开全面测试，
若有问题，请及时提交 issues或PR，多谢 :))"
Update 2.2_tensor.md,"1.补全括号
2.官方文档上无badbmm函数，应为baddbmm"
Update 2.2_tensor.md,"1.补全括号
2.badbmm -> baddbmm"
Update 2.2_tensor.md,补全括号
我重新制作了PDF版本，修复了公式和图片问题，希望推上主链,
Add files via upload,fix some bug of PDF
Patch 1,"I see that somebody want a PDF book, I made it "
3.12 weight decay 图片放错了,最后一个图片放错啦
关于3.13章丢弃法的疑惑,"``` python
def dropout(X, drop_prob):
    X = X.float()
    assert 0 <= drop_prob <= 1
    keep_prob = 1 - drop_prob
    # 这种情况下把全部元素都丢弃
    if keep_prob == 0:
        return torch.zeros_like(X)
    mask = (torch.randn(X.shape) < keep_prob).float()
    
    return mask * X / keep_prob
```
此处randn生成的数不是分布在0-1之间，导致drop_prob为0时也会产生丢弃。
``` python
X = torch.arange(16).view(2, 8)
dropout(X, 0)
```
```
tensor([[ 0.,  0.,  2.,  3.,  4.,  5.,  6.,  7.],
        [ 8.,  9., 10.,  0., 12., 13., 14., 15.]])
```"
公式一个都看不到，想看又看不下去，真是难受,
二维卷积层那一块初始化tensor时没有指明类型，导致后续运算会报错,"x = torch.ones(6, 8, dtype=torch.float)
x[:, 2:6] = 0
k = torch.tensor([[1, -1]], dtype=torch.float)
y = corr2d(x, k)

RuntimeError: expected backend CPU and dtype Float but got backend CPU and dtype Long"
能否先根据目前的版本制作一个pdf，方便推广,"请问能否根据现在目前已有的版本生成一个pdf，这样阅读起来方便，阅读的人也会增加很多，方便项目推广。大家边阅读边反馈，最终版的质量会提高很多。
如果你们方便的话。"
2.2.4 运算的内存开销 中关于view之后是否是同一id的疑惑,"教程中的表述，虽然没有明说，不过给人感觉是view这种操作不会改变id值。

但在我试验中，tensor在view之后，会变为新的id。如下代码：

```python
x = torch.randn(1,2)
print(x)
y = x.view(1,2)
print(y)
print(id(x) == id(y))

```

> tensor([[-0.7329, -1.4493]])
tensor([[-0.7329, -1.4493]])
False


不过使用torch自带的equal可以正确检查这两个是不是指向同一个tensor：


```python
x = torch.zeros(3, 5)
y = x.view(3, 5)

print(torch.equal(x, y))
```

> True

不过equal函数要求tensor有相同的size和elements。"
关于Chap02中2.3_autograd.ipynb的疑问,"原文中写到

> 如果我们想要修改tensor的数值，但是又不希望被autograd记录（即不会影响反向传播），那么我么可以对tensor.data进行操作.

```
In [14]:
x = torch.ones(1,requires_grad=True)

print(x.data) # 还是一个tensor
print(x.data.requires_grad) # 但是已经是独立于计算图之外

y = 2 * x
x.data *= 100 # 只改变了值，不会记录在计算图，所以不会影响梯度传播

y.backward()
print(x) # 更改data的值也会影响tensor的值
print(x.grad)
```

-----------输出结果-----------
tensor([1.])
False
tensor([100.], requires_grad=True)
tensor([2.])

我做了些尝试性的改变，发现输出了一些我无法理解的结果，比如把`y = 2 * x
`改成`y = 2 * x * x`时，`print(x.grad)`的输出结果变成`202`；如果把`y = 2 * x`改成`y = 2 * x * x * x`，`print(x.grad)`的输出结果变成`20202`。

虽然结果似乎有一定的规律，但是我没找到。这种情况下应该怎么解释呢？"
麻烦请求作者先放一个PDF版本合集 .md文件下载后 有大量公式显示不全 阅读障碍严重,
3.3.4节报错：'LinearNet' object does not support indexing,"python版本为3.6.3
pytorch版本为1.2.0

建议将原代码
```python
init.normal_(net[0].weight, mean=0, std=0.01)
init.constant_(net[0].bias, val=0)  # 也可以直接修改bias的data: net[0].bias.data.fill_(0)
```
更改为：
```python
init.normal_(net.linear.weight, mean=0, std=0.01)
init.constant_(net.linear.bias, val=0)  # 也可以直接修改bias的data: net[0].bias.data.fill_(0)
```"
能不能增加requirements.txt,执行后，总是少模块，还得关掉jupyter安装，又来一遍。然后又提示少其他模块。
李沐，这事怎么搞成“为他人作嫁衣裳”啦~~,
许多公式的制版都是混乱的，需要阅读时在原文和这里跳转，影响阅读和项目的推广,
公式都是laTex格式，没有被转换,
大概什么时候能更新完毕呢？目前和原书相比还差哪些章节呢？,
Update the define of 'b',"torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) → Tensor
size (int...) – a sequence of integers defining the shape of the output tensor. Can be a variable number of arguments or a collection like a list or tuple.

If use shape=(1,) will return an error. And if not define the type of b it will be error when using linreg function. 
(The specific error messages is: expected device cpu and dtype Double but got device cpu and dtype Float)
Because in linreg, torch.mm(X, w) is torch.float64, and b is torch.float32, they add up cannot return torch.float64."
import numpy library,"If not import this library, it will be with error when define labels."
关于第九章的一些疑问,在mxnet原作9.4中，涉及到了MultiBoxTarget、MultiBoxPrior、MultiBoxDetection这几个库函数。我想探讨下在pytorch中相对应的库函数是什么呢？还是说只能自己手动实现这些功能？
4.1 doc结尾出现错误,"Sequential、ModuleList、ModuleDict类继承自BlModuleock类。
最后应该是继承Module类吧。
感谢大佬给初学者提供PyTorch框架版！"
